[tox]
min_version = 4.0
envlist = 
    py312
    lint
    typecheck
    security
    coverage-report

[testenv]
description = Run unit tests with pytest
package = wheel
deps = 
    -e.[test]
extras = test
commands = 
    pytest tests/unit/ {posargs}

[testenv:integration]
description = Run integration tests
deps = 
    -e.[test]
commands = 
    pytest tests/integration/ {posargs}

[testenv:property]
description = Run property-based tests
deps = 
    -e.[test]
commands = 
    pytest tests/property/ {posargs} --hypothesis-show-statistics

[testenv:benchmark]
description = Run performance benchmarks
deps = 
    -e.[test]
commands = 
    pytest tests/benchmarks/ {posargs} --benchmark-json=benchmark-results.json

[testenv:load]
description = Run load tests (short duration for CI)
deps = 
    -e.[test]
setenv = 
    LOAD_TEST_DURATION = short
commands = 
    pytest tests/load/ {posargs} -k "not long_running"

[testenv:coverage]
description = Run tests with coverage reporting
deps = 
    -e.[test]
commands = 
    pytest tests/unit/ tests/integration/ --cov=maker_kit --cov-report=xml --cov-report=html --cov-report=term-missing {posargs}

[testenv:coverage-report]
description = Generate and display coverage report
deps = 
    coverage[toml]
skip_install = true
commands = 
    coverage combine
    coverage report
    coverage html

[testenv:lint]
description = Run code linting with ruff
deps = 
    ruff
skip_install = true
commands = 
    ruff check maker_kit/ tests/ {posargs}

[testenv:format]
description = Run code formatting
deps = 
    black
    isort
skip_install = true
commands = 
    black maker_kit/ tests/ {posargs}
    isort maker_kit/ tests/ {posargs}

[testenv:format-check]
description = Check code formatting without making changes
deps = 
    black
    isort
skip_install = true
commands = 
    black --check maker_kit/ tests/ {posargs}
    isort --check-only maker_kit/ tests/ {posargs}

[testenv:typecheck]
description = Run type checking with mypy
deps = 
    mypy
    -e.[test]
commands = 
    mypy maker_kit/ {posargs}

[testenv:security]
description = Run security scans
deps = 
    safety
    bandit[toml]
skip_install = true
commands = 
    safety check --ignore=70612
    bandit -r maker_kit/ -f json -o bandit-report.json

[testenv:docs]
description = Build documentation
deps = 
    -e.[docs]
commands = 
    sphinx-build -W -b html docs/ docs/_build/html

[testenv:docs-serve]
description = Build and serve documentation
deps = 
    -e.[docs]
    sphinx-autobuild
commands = 
    sphinx-autobuild docs/ docs/_build/html --host 0.0.0.0 --port 8000

[testenv:build]
description = Build package for distribution
deps = 
    build
    twine
skip_install = true
commands = 
    python -m build
    twine check dist/*

[testenv:clean]
description = Clean up build artifacts and cache
skip_install = true
allowlist_externals = 
    rm
    find
commands = 
    rm -rf build/
    rm -rf dist/
    rm -rf .eggs/
    rm -rf *.egg-info/
    rm -rf .pytest_cache/
    rm -rf .coverage
    rm -rf htmlcov/
    rm -rf .mypy_cache/
    rm -rf __pycache__/
    find . -type d -name __pycache__ -delete
    find . -type f -name "*.pyc" -delete

[testenv:dev]
description = Development environment with all dependencies
deps = 
    -e.[all]
commands = 
    python --version
    pip list

# Test matrix for different Python versions
[testenv:py{312}]
description = Run tests on Python {basepython}

# Parallel testing configuration
[testenv:parallel]
description = Run tests in parallel
deps = 
    -e.[test]
    pytest-xdist
commands = 
    pytest tests/unit/ tests/integration/ -n auto {posargs}

# Quick smoke test
[testenv:smoke]
description = Run smoke tests for quick validation
deps = 
    -e.[test]
commands = 
    pytest tests/ -m smoke {posargs}

# Full test suite
[testenv:full]
description = Run complete test suite
deps = 
    -e.[test]
commands = 
    pytest tests/unit/ tests/integration/ tests/property/ --cov=maker_kit {posargs}

# Performance regression testing
[testenv:regression]
description = Run performance regression tests
deps = 
    -e.[test]
setenv = 
    BENCHMARK_COMPARE = true
commands = 
    pytest tests/benchmarks/ --benchmark-json=current-benchmark.json
    python scripts/check_performance_regression.py --current current-benchmark.json --baseline performance-baselines/main-baseline.json

[flake8]
max-line-length = 100
extend-ignore = E203, W503
per-file-ignores = 
    tests/*: S101
exclude = 
    .git,
    .tox,
    build,
    dist,
    *.egg-info,
    .venv

[coverage:run]
source = maker_kit
parallel = true
branch = true

[coverage:report]
show_missing = true
skip_covered = false
fail_under = 80